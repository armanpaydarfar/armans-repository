import random
import sys
import time
import heapq
import numpy
# You can use the functions in othello_shared to write your AI 
from othello_shared import get_possible_moves, play_move, compute_utility

import logging
############ MINIMAX ###############################

"""
Computes the minimax value of a MAX node
"""
def minimax_max_node(board):

    if get_possible_moves(board,1) == []:
        return compute_utility(board)
    
    v = -float("inf")
    actions = get_possible_moves(board,1)

    for action in actions:
        next_board = play_move(board,1,action[0],action[1])
        v = max(v, minimax_min_node(next_board))

    return v


"""
Computes the minimax value of a MIN node
"""
def minimax_min_node(board):

    if get_possible_moves(board,2) == []:
        return compute_utility(board)
    v = float("inf")
    
    actions = get_possible_moves(board,2)
    for action in actions:
        next_board = play_move(board,2,action[0],action[1])
        v = min(v, minimax_max_node(next_board))

    return v


"""
Given a board and a player color, decide on a move. 
The return value is a tuple of integers (i,j), where
i is the column and j is the row on the board.  
"""
def select_move_minimax(board, color):
    actions= get_possible_moves(board,color)

    v = []
    for i in range(len(actions)):
        current_action = actions[i]
        new_board = play_move(board,color,current_action[0],current_action[1])
        if color == 1:
            v.append(minimax_min_node(new_board))
        else:
            v.append(minimax_max_node(new_board))
    
    if color == 1:    
        k = numpy.argmax(v)
    
    else:
        k = numpy.argmin(v)
    
    final_i,final_j = actions[k]
    
    return final_i,final_j

    
############ ALPHA-BETA PRUNING #####################

"""
Computes the minimax value of a MAX node with alpha-beta pruning
"""
def alphabeta_max_node(board, alpha, beta, level=1, limit=float("inf")):
    if get_possible_moves(board,1) == [] or level == limit:
       return compute_utility(board)
    v = -float("inf")
    actions = get_possible_moves(board,1)
    utility_heap = []
    
    for action in actions:
        new_board = play_move(board,1,action[0],action[1])
        heapq.heappush(utility_heap,(-compute_utility(new_board),new_board))        

    for i in range(len(actions)):
        _,next_board = heapq.heappop(utility_heap)
        v = max(v, alphabeta_min_node(next_board,alpha,beta,level+1,limit))
        if v >= beta:
            return v
        alpha = max(alpha,v)
    return v


"""
Computes the minimax value of a MIN node with alpha-beta pruning
"""
def alphabeta_min_node(board, alpha, beta, level=1, limit=float("inf")):
    if get_possible_moves(board,2) == [] or level == limit:
        return compute_utility(board)
    v = float("inf")
    actions = get_possible_moves(board,2)
    utility_heap = []  
    
    for action in actions:
        new_board = play_move(board, 2, action[0],action[1])
        heapq.heappush(utility_heap,(compute_utility(new_board),new_board))
        
    for i in range(len(actions)):
        _,next_board = heapq.heappop(utility_heap)
        v = min(v, alphabeta_max_node(next_board,alpha,beta,level+1,limit))
        if v<=alpha:
            return v
        
        beta = min(beta,v)
    return v


"""
Given a board and a player color, decide on a move. 
The return value is a tuple of integers (i,j), where
i is the column and j is the row on the board.  
"""
def select_move_alphabeta(board, color, limit=float("inf")):
    
    
    
    
    actions= get_possible_moves(board,color)
    v = []
    act = []
   
    
    utility_heap = []
    
    
    if color ==1:
        
        for i in range(len(actions)):
            current_action = actions[i]
            new_board = play_move(board,color,current_action[0],current_action[1])
            heapq.heappush(utility_heap, (-compute_utility(new_board),current_action,new_board))            
    
        for i in range(len(actions)):
            _,current_action,current_board = heapq.heappop(utility_heap)
            v_current = alphabeta_min_node(current_board,-float("inf"),float("inf"),2,limit)
            v.append(v_current)
            act.append(current_action)
        k = numpy.argmax(v)
            
    else:
        for i in range(len(actions)):
            current_action = actions[i]
            new_board = play_move(board,color,current_action[0],current_action[1])
            heapq.heappush(utility_heap,(compute_utility(new_board),current_action,new_board))
                
        for i in range(len(actions)):
            _,current_action,current_board = heapq.heappop(utility_heap)
            v_current = alphabeta_max_node(current_board,-float("inf"),float("inf"),2,limit)
            v.append(v_current)
            act.append(current_action)
            
            
        k = numpy.argmin(v)

    
       
    final_i,final_j = act[k]

    return final_i,final_j    
    


####################################################
def run_ai():
    """
    This function establishes communication with the game manager. 
    It first introduces itself and receives its color. 
    Then it repeatedly receives the current score and current board state
    until the game is over. 
    """
    print("Minimax AI") # First line is the name of this AI  
    color = int(input()) # Then we read the color: 1 for dark (goes first), 
                         # 2 for light. 

    while True: # This is the main loop 
        # Read in the current game status, for example:
        # "SCORE 2 2" or "FINAL 33 31" if the game is over.
        # The first number is the score for player 1 (dark), the second for player 2 (light)
        next_input = input() 
        status, dark_score_s, light_score_s = next_input.strip().split()
        dark_score = int(dark_score_s)
        light_score = int(light_score_s)

        if status == "FINAL": # Game is over. 
            print 
        else: 
            board = eval(input()) # Read in the input and turn it into a Python
                                  # object. The format is a list of rows. The 
                                  # squares in each row are represented by 
                                  # 0 : empty square
                                  # 1 : dark disk (player 1)
                                  # 2 : light disk (player 2)
                    
            # Select the move and send it to the manager 
            #movei, movej = select_move_minimax(board, color)
            movei, movej = select_move_alphabeta(board, color,7)
            print("{} {}".format(movei, movej)) 


if __name__ == "__main__":
    logging.basicConfig(filename="info.log", level=logging.INFO)

    run_ai()
